{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv8edNY2Z2pq"
      },
      "source": [
        "# Tokenizing data collected from Wikipedia\n",
        "\n",
        "Emilio Lehoucq - 5/21/24\n",
        "\n",
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F73v60oZaF_J",
        "outputId": "c90eaa47-b4c1-4d2c-e7e8-f64390e294d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/emiliolehoucq/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/emiliolehoucq/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/emiliolehoucq/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB9l-VHlcAIE"
      },
      "source": [
        "## Defining functions for this script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3gcQ_pUgcDQL"
      },
      "outputs": [],
      "source": [
        "def remove_urls(text, replacement_text=\"\"):\n",
        "  \"\"\"\n",
        "  Function to remove URLs from a string.\n",
        "  Input: text (string), replacement_text (string)\n",
        "  Output: text_without_urls (string)\n",
        "  Dependencies: re\n",
        "  Taken from: https://www.geeksforgeeks.org/remove-urls-from-string-in-python/\n",
        "  \"\"\"\n",
        "  # Define a regex pattern to match URLs\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+') # https?:// protocol (optional s), \\S+ one or more non-white space characters, | or, www\\.\\S+ URLs starting with www.\n",
        "  # Use the sub() method to replace URLs with the specified replacement text\n",
        "  text_without_urls = url_pattern.sub(replacement_text, str(text))\n",
        "  return text_without_urls\n",
        "\n",
        "def tokenizer(article):\n",
        "  \"\"\"\n",
        "  Function to tokenize articles.\n",
        "  Input: article (string)\n",
        "  Output: unigrams, stems, lemmas, bigrams, bigrams_stems, bigrams_lemmas, trigrams, trigrams_stems, trigrams_lemmas (tuple)\n",
        "  Dependencies: NLTK\n",
        "  \"\"\"\n",
        "  # Remove URLs from article\n",
        "  article = remove_urls(article)\n",
        "  # Create variables to store unigrams, stems, and lemmas\n",
        "  unigrams, stems, lemmas = [], [], []\n",
        "  # Tokenize into unigrams, stems, and lemmas\n",
        "  for unigram in nltk.word_tokenize(str(article)):\n",
        "    # Lowercase\n",
        "    unigram = unigram.lower()\n",
        "    # Keep only alphanumeric and remove stopwords\n",
        "    if unigram.isalnum() and unigram not in stopwords:\n",
        "      # Store unigrams\n",
        "      unigrams.append(unigram)\n",
        "      # Store stems\n",
        "      stems.append(nltk.PorterStemmer().stem(unigram))\n",
        "      # Store lemmas\n",
        "      lemmas.append(nltk.WordNetLemmatizer().lemmatize(unigram))\n",
        "  # Create lists of bigrams\n",
        "  bigrams = list(nltk.bigrams(unigrams))\n",
        "  bigrams_stems = list(nltk.bigrams(stems))\n",
        "  bigrams_lemmas = list(nltk.bigrams(lemmas))\n",
        "  # Create lists of trigrams\n",
        "  trigrams = list(nltk.trigrams(unigrams))\n",
        "  trigrams_stems = list(nltk.trigrams(stems))\n",
        "  trigrams_lemmas = list(nltk.trigrams(lemmas))\n",
        "  # Return tuple with everything\n",
        "  return unigrams, stems, lemmas, bigrams, bigrams_stems, bigrams_lemmas, trigrams, trigrams_stems, trigrams_lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmJdzWwuaIOF"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "189A5iVZaLal",
        "outputId": "e15a6437-c471-4a64-f955-48504c490eb9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data_raw_wikipedia_4_17_2024.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em2_xgIIaPwN"
      },
      "source": [
        "## Tokenizing articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ZEnyYRNaT8E"
      },
      "outputs": [],
      "source": [
        "# Define columns to store results\n",
        "df['text_unigrams'] = None\n",
        "df['text_stems'] = None\n",
        "df['text_lemmas'] = None\n",
        "df['text_bigrams'] = None\n",
        "df['text_bigrams_stems'] = None\n",
        "df['text_bigrams_lemmas'] = None\n",
        "df['text_trigrams'] = None\n",
        "df['text_trigrams_stems'] = None\n",
        "df['text_trigrams_lemmas'] = None\n",
        "\n",
        "# Iterate over rows of the data frame\n",
        "for i, row in df.iterrows():\n",
        "  # Tokenize article\n",
        "  unigrams, stems, lemmas, bigrams, bigrams_stems, bigrams_lemmas, trigrams, trigrams_stems, trigrams_lemmas = tokenizer(row['text'])\n",
        "  # Store results\n",
        "  df.at[i, 'text_unigrams'] = unigrams\n",
        "  df.at[i, 'text_stems'] = stems\n",
        "  df.at[i, 'text_lemmas'] = lemmas\n",
        "  df.at[i, 'text_bigrams'] = bigrams\n",
        "  df.at[i, 'text_bigrams_stems'] = bigrams_stems\n",
        "  df.at[i, 'text_bigrams_lemmas'] = bigrams_lemmas\n",
        "  df.at[i, 'text_trigrams'] = trigrams\n",
        "  df.at[i, 'text_trigrams_stems'] = trigrams_stems\n",
        "  df.at[i, 'text_trigrams_lemmas'] = trigrams_lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Nwuf2selrz"
      },
      "source": [
        "## Make sure data frame looks as expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "RiQMxnRNfI7f",
        "outputId": "d6edcd35-4e35-4266-f70b-806e1ff39ff8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_unigrams</th>\n",
              "      <th>text_stems</th>\n",
              "      <th>text_lemmas</th>\n",
              "      <th>text_bigrams</th>\n",
              "      <th>text_bigrams_stems</th>\n",
              "      <th>text_bigrams_lemmas</th>\n",
              "      <th>text_trigrams</th>\n",
              "      <th>text_trigrams_stems</th>\n",
              "      <th>text_trigrams_lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[mindfulness, wikipedia, jump, content, main, ...</td>\n",
              "      <td>[mind, wikipedia, jump, content, main, menu, m...</td>\n",
              "      <td>[mindfulness, wikipedia, jump, content, main, ...</td>\n",
              "      <td>[(mindfulness, wikipedia), (wikipedia, jump), ...</td>\n",
              "      <td>[(mind, wikipedia), (wikipedia, jump), (jump, ...</td>\n",
              "      <td>[(mindfulness, wikipedia), (wikipedia, jump), ...</td>\n",
              "      <td>[(mindfulness, wikipedia, jump), (wikipedia, j...</td>\n",
              "      <td>[(mind, wikipedia, jump), (wikipedia, jump, co...</td>\n",
              "      <td>[(mindfulness, wikipedia, jump), (wikipedia, j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[mudita, wikipedia, jump, content, main, menu,...</td>\n",
              "      <td>[mudita, wikipedia, jump, content, main, menu,...</td>\n",
              "      <td>[mudita, wikipedia, jump, content, main, menu,...</td>\n",
              "      <td>[(mudita, wikipedia), (wikipedia, jump), (jump...</td>\n",
              "      <td>[(mudita, wikipedia), (wikipedia, jump), (jump...</td>\n",
              "      <td>[(mudita, wikipedia), (wikipedia, jump), (jump...</td>\n",
              "      <td>[(mudita, wikipedia, jump), (wikipedia, jump, ...</td>\n",
              "      <td>[(mudita, wikipedia, jump), (wikipedia, jump, ...</td>\n",
              "      <td>[(mudita, wikipedia, jump), (wikipedia, jump, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[buddhism, pakistan, wikipedia, jump, content,...</td>\n",
              "      <td>[buddhism, pakistan, wikipedia, jump, content,...</td>\n",
              "      <td>[buddhism, pakistan, wikipedia, jump, content,...</td>\n",
              "      <td>[(buddhism, pakistan), (pakistan, wikipedia), ...</td>\n",
              "      <td>[(buddhism, pakistan), (pakistan, wikipedia), ...</td>\n",
              "      <td>[(buddhism, pakistan), (pakistan, wikipedia), ...</td>\n",
              "      <td>[(buddhism, pakistan, wikipedia), (pakistan, w...</td>\n",
              "      <td>[(buddhism, pakistan, wikipedia), (pakistan, w...</td>\n",
              "      <td>[(buddhism, pakistan, wikipedia), (pakistan, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[art, wikipedia, jump, content, main, menu, ma...</td>\n",
              "      <td>[art, wikipedia, jump, content, main, menu, ma...</td>\n",
              "      <td>[art, wikipedia, jump, content, main, menu, ma...</td>\n",
              "      <td>[(art, wikipedia), (wikipedia, jump), (jump, c...</td>\n",
              "      <td>[(art, wikipedia), (wikipedia, jump), (jump, c...</td>\n",
              "      <td>[(art, wikipedia), (wikipedia, jump), (jump, c...</td>\n",
              "      <td>[(art, wikipedia, jump), (wikipedia, jump, con...</td>\n",
              "      <td>[(art, wikipedia, jump), (wikipedia, jump, con...</td>\n",
              "      <td>[(art, wikipedia, jump), (wikipedia, jump, con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[roman, empire, wikipedia, jump, content, main...</td>\n",
              "      <td>[roman, empir, wikipedia, jump, content, main,...</td>\n",
              "      <td>[roman, empire, wikipedia, jump, content, main...</td>\n",
              "      <td>[(roman, empire), (empire, wikipedia), (wikipe...</td>\n",
              "      <td>[(roman, empir), (empir, wikipedia), (wikipedi...</td>\n",
              "      <td>[(roman, empire), (empire, wikipedia), (wikipe...</td>\n",
              "      <td>[(roman, empire, wikipedia), (empire, wikipedi...</td>\n",
              "      <td>[(roman, empir, wikipedia), (empir, wikipedia,...</td>\n",
              "      <td>[(roman, empire, wikipedia), (empire, wikipedi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text_unigrams  \\\n",
              "0  [mindfulness, wikipedia, jump, content, main, ...   \n",
              "1  [mudita, wikipedia, jump, content, main, menu,...   \n",
              "2  [buddhism, pakistan, wikipedia, jump, content,...   \n",
              "3  [art, wikipedia, jump, content, main, menu, ma...   \n",
              "4  [roman, empire, wikipedia, jump, content, main...   \n",
              "\n",
              "                                          text_stems  \\\n",
              "0  [mind, wikipedia, jump, content, main, menu, m...   \n",
              "1  [mudita, wikipedia, jump, content, main, menu,...   \n",
              "2  [buddhism, pakistan, wikipedia, jump, content,...   \n",
              "3  [art, wikipedia, jump, content, main, menu, ma...   \n",
              "4  [roman, empir, wikipedia, jump, content, main,...   \n",
              "\n",
              "                                         text_lemmas  \\\n",
              "0  [mindfulness, wikipedia, jump, content, main, ...   \n",
              "1  [mudita, wikipedia, jump, content, main, menu,...   \n",
              "2  [buddhism, pakistan, wikipedia, jump, content,...   \n",
              "3  [art, wikipedia, jump, content, main, menu, ma...   \n",
              "4  [roman, empire, wikipedia, jump, content, main...   \n",
              "\n",
              "                                        text_bigrams  \\\n",
              "0  [(mindfulness, wikipedia), (wikipedia, jump), ...   \n",
              "1  [(mudita, wikipedia), (wikipedia, jump), (jump...   \n",
              "2  [(buddhism, pakistan), (pakistan, wikipedia), ...   \n",
              "3  [(art, wikipedia), (wikipedia, jump), (jump, c...   \n",
              "4  [(roman, empire), (empire, wikipedia), (wikipe...   \n",
              "\n",
              "                                  text_bigrams_stems  \\\n",
              "0  [(mind, wikipedia), (wikipedia, jump), (jump, ...   \n",
              "1  [(mudita, wikipedia), (wikipedia, jump), (jump...   \n",
              "2  [(buddhism, pakistan), (pakistan, wikipedia), ...   \n",
              "3  [(art, wikipedia), (wikipedia, jump), (jump, c...   \n",
              "4  [(roman, empir), (empir, wikipedia), (wikipedi...   \n",
              "\n",
              "                                 text_bigrams_lemmas  \\\n",
              "0  [(mindfulness, wikipedia), (wikipedia, jump), ...   \n",
              "1  [(mudita, wikipedia), (wikipedia, jump), (jump...   \n",
              "2  [(buddhism, pakistan), (pakistan, wikipedia), ...   \n",
              "3  [(art, wikipedia), (wikipedia, jump), (jump, c...   \n",
              "4  [(roman, empire), (empire, wikipedia), (wikipe...   \n",
              "\n",
              "                                       text_trigrams  \\\n",
              "0  [(mindfulness, wikipedia, jump), (wikipedia, j...   \n",
              "1  [(mudita, wikipedia, jump), (wikipedia, jump, ...   \n",
              "2  [(buddhism, pakistan, wikipedia), (pakistan, w...   \n",
              "3  [(art, wikipedia, jump), (wikipedia, jump, con...   \n",
              "4  [(roman, empire, wikipedia), (empire, wikipedi...   \n",
              "\n",
              "                                 text_trigrams_stems  \\\n",
              "0  [(mind, wikipedia, jump), (wikipedia, jump, co...   \n",
              "1  [(mudita, wikipedia, jump), (wikipedia, jump, ...   \n",
              "2  [(buddhism, pakistan, wikipedia), (pakistan, w...   \n",
              "3  [(art, wikipedia, jump), (wikipedia, jump, con...   \n",
              "4  [(roman, empir, wikipedia), (empir, wikipedia,...   \n",
              "\n",
              "                                text_trigrams_lemmas  \n",
              "0  [(mindfulness, wikipedia, jump), (wikipedia, j...  \n",
              "1  [(mudita, wikipedia, jump), (wikipedia, jump, ...  \n",
              "2  [(buddhism, pakistan, wikipedia), (pakistan, w...  \n",
              "3  [(art, wikipedia, jump), (wikipedia, jump, con...  \n",
              "4  [(roman, empire, wikipedia), (empire, wikipedi...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.filter(regex='^text_').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4IRerrOfh1j"
      },
      "source": [
        "## Export data to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JaiP4qqxgGp_"
      },
      "outputs": [],
      "source": [
        "df.to_csv('data_tokenized_wikipedia_5_21_24.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
